Uses of "update" in Marlin:

- onRecordTaskCommit, easy case: set timeCommitted, retried=(true|false) on
  associated "Error" objects.
- onRecordTaskCommit, hard case 1: update all taskoutputs for a reduce task that
  is being retried
- onRecordTaskCommit, hard case 2: update all taskinputs for a reduce task that
  has NOT been retried to set wantInputRemoved
- onTaskRetryReduce: update all taskinputs for a reduce task that IS being
  retried
- jobCancelRecords: update jobinputs, taskinputs, taskoutputs to set
  timeJobCancelled=* (NOTE: also using the wrong filter)
- agentFailTasks: set state=done, result=fail on tasks operated by an agent
- jobMarkInputs: set domain=us for taskinputs
- jobSave: set timeJobCancelled, timeCancelled on job-related records

Summary of changes:

(1) Update error (onRecordTaskCommit #3): trivial (done)

(2) Marking inputs (done).  We just do this N at a time, and trigger another
    round if we've hit our limit.  There's only one way this could be entered
    concurrently, and in that case this would do the right thing.

(3) Task abandonment (agentFailTasks) (done).  This is called in three contexts:

  - agentTimeout: with no extra filter, and invoked continually while the agent
    is out to lunch
  - agentStarted: with filter on agentGeneration (safe to retry/ignore result as
    long as the generation doesn't become *newer*), although if the agent
    restarts multiple times rapidly, we may end up issuing a bunch of these
    concurrently
  - jobAssigned: with filter on agentGeneration (safe to retry/ignore result as
    long as the generation doesn't become *newer*), although if the job gets
    dropped and reassigned rapidly, we may end up issuing a bunch of these
    concurrently

  In all cases, when we issue a request, if we hit the limit, we re-issue it
  again.

  In the timeout case, if we get called when one's already pending, we can
  safely ignore that because we know we've got such an update in-progress.
  We'll subsequently either trigger it again or catch an agentStarted event,
  which will update any tasks in progress at the time.

  In the agentStarted case, if we get called while there's one pending,
  presumably the generation will be different.  (If it's not, somehow, we'll
  want to trigger another round of updates for that generation when this one
  completes.)  In that case, we'll want to schedule another update to happen
  based on the new generation.  We also probably want to switch to "<=" instead
  of "!=" so we can avoid abandoning *newer* tasks in the case of multiple rapid
  restarts.

  In the jobAssigned case, the behavior is the same as for the agentStarted
  case, though it's more likely that we would see concurrent updates issued for
  the same current agent generation.

(4) Update taskoutputs for propagation (onRecordTaskCommit #1) (done):

    - If nOutputs is less than the limit, do the same thing we're doing today.
    - If nOutputs is greater than the limit, set timePropagateStarted on the
      task record.
    - Add a new query for timePropagateStarted && !timePropagateDone.  In this
      query, do a server-side update.  When done, set timePropagateDone.

(5) Update taskinputs for input removal (onRecordTaskCommit #2) (done):

    - In the context of the barrier, set timeCleanupStarted.  (Might want to
      rename this, since it's not the actual cleanup operation itself.)
    - Have a separate query for timeCleanupStarted && !timeCleanupDone.
      Each time through the loop for this query, do update up to N taskinputs.
      When we finish marking all the inputs for cleanup, set timeCleanupDone.

(6) Retrying reduce tasks (onTaskRetryReduce) (done):

    - In the context of the barrier, set timeRetryStarted, retryTaskId,
      retryMantaComputeId, retryAgentGeneration, and write the new task with a
      field indicating that it's not yet ready (e.g., "retryInProgress": true).
    - Add a new query for timeRetryStarted && !timeRetryDone.  Each time through
      the loop for this query, update up to N taskinputs.  When it's 0, update
      the existing task to set timeRetryDone, and update the new task to state
      "dispatched".
    - Have the taskCommit query *exclude* tasks with retryInProgress set.  This
      way, the retried task essentially cannot fail until the first one has been
      completely retried, but abandonment and early failure by the agent will
      still do the right thing.
    - wqJobTasksReduce probably needs to have !(timeRetryStarted), or else use
      existing field timeRetried to refer to timeRetryStarted.

(7) Cancellation (jobSave, jobCancelRecords):

  This one currently needs to be transactional because we're going to drop this
  job as soon as this request completes, and we're not going to look for new job
  cancellations until we finish that.  We can't actually block the subscription
  on having cancelled all records because other components can continue writing
  out new records.  We're going to want to:

  - Add a new field to the job called timeCancelledRead which we write
    synchronously with respect to the bus subscription.
  - When we write this on a job, we start cancelling records, and we keep doing
    so until we drop the job.
  - We consider the job done when there are no uncommitted tasks (i.e., we
    ignore p_nunpropagated, p_nretryneeded, and p_ndispatches).
  - When we load a job, if timeCancelledRead (and by construction state !=
    "done"), we enter the same loop that cancels records in batches until we
    drop the job.

  The normal flow will be:
  - user cancels job, writing timeCancelled
  - supervisor immediately writes timeCancelledRead
  - when that completes cancel a batch of tasks
  - eventually we commit all outstanding tasks and the jobsupervisor sets
    state = "done".

  I considered an option where agents periodically check for cancelled jobs, but
  "dispatched" tasks need to be updated anyway, so this would only really help
  "accepted" tasks, which agents need to do something for anyway, so it's not
  much help.
